max_steps = 200
batch_size = 128
micro_batch_size = 16
seq_len = 8192
rollouts_per_example = 16
mask_truncated_completions = false

[model]
name = "Qwen/Qwen3-4B-Thinking-2507"

[sampling]
max_tokens = 8192

[environment]
id = "haiku"

[environment.args]
use_thinking = true
min_length = 2048
max_length = 16384

[ckpt]
interval = 25
